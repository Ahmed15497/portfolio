{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXJRDnWoa5gf"
      },
      "source": [
        "# **Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dv5opgTrsLN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "y8LJ6epTJhRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/datajpg/train.csv /content/dataset"
      ],
      "metadata": {
        "id": "wvbPxrpMJs8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePj-gnO0IB74"
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynf5Ki9UPQaB"
      },
      "outputs": [],
      "source": [
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNEGRs3mHar1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from skimage.filters import threshold_otsu\n",
        "import imgaug.augmenters as iaa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEwWqT9Ya-S_"
      },
      "source": [
        "# **Downloading dataset from kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Hmuz2gHiWn"
      },
      "outputs": [],
      "source": [
        "# **Downloading the dataset using kaggle API**\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeM5w4Y_HkfU"
      },
      "outputs": [],
      "source": [
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHLm1HG1HsXm"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "# copy the json file to the folder .kaggle in the root directory\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# change folder permissions to be able to read and write\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!pwd\n",
        "\n",
        "!mkdir dataset\n",
        "\n",
        "%cd /content/dataset\n",
        "\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jNlRIeQHVKQ"
      },
      "outputs": [],
      "source": [
        "# -f folder name\n",
        "!kaggle competitions download -c siim-isic-melanoma-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-muTZUCGPYlR"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c siim-isic-melanoma-classification -f \"train.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJTZO0WrMlPq"
      },
      "source": [
        "# **Downloading dataset from website**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/dataset"
      ],
      "metadata": {
        "id": "gKPQy5u5J5FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvGQ8LXZM5lE"
      },
      "outputs": [],
      "source": [
        "!wget \"https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_JPEG.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gri1dY_0bD77"
      },
      "source": [
        "# **Unzipping dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaMVGYHjP93V"
      },
      "outputs": [],
      "source": [
        "#!mkdir dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vUXs7IlQFSK"
      },
      "outputs": [],
      "source": [
        "#%cd dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY6RsgMmQNDE"
      },
      "outputs": [],
      "source": [
        "#!mv /content/ISIC_2020_Training_JPEG.zip /content/dataset/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FDpGzzdPisU"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/dataset/ISIC_2020_Training_JPEG.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KaiS7ScKIvl"
      },
      "outputs": [],
      "source": [
        "#!unzip \"/content/dataset/train.csv.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ_o99fOKJAR"
      },
      "outputs": [],
      "source": [
        "main_path = \"/content/dataset/train\"\n",
        "len(os.listdir(main_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hysl9WRCPGQv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/dataset/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjChYoeMT6fA"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qDozbtGPtKO"
      },
      "outputs": [],
      "source": [
        "df['image_name_'] = df['image_name'].apply(lambda x: f\"{main_path}/{x}.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awQtIX1RUGr7"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0sR2p3AQCKj"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(f\"{main_path}/ISIC_0149568.jpg\")\n",
        "#cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "AmM0adLHl2hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd-LwtMSXSK3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['image_name_'].to_list(), df['target'].to_list(), test_size=0.1, random_state=42, stratify=df['target'].to_list())\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af7s-7keZIN7"
      },
      "outputs": [],
      "source": [
        "oversample = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "X_over, y_over = oversample.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww34qHJYavEN"
      },
      "outputs": [],
      "source": [
        "X_over_list = []\n",
        "for i in range(len(X_over)):\n",
        "  X_over_list.append(X_over[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWpl8NpSbqzU"
      },
      "outputs": [],
      "source": [
        "len(X_over_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZPzfgz2AMMy"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "  'Generates data for Keras'\n",
        "  def __init__(self, list_IDs, labels, batch_size=16, dim=(128,128), n_channels=1,\n",
        "              n_classes=2, shuffle=True, augmentation=True, segmentation=True):\n",
        "    'Initialization'\n",
        "    self.dim = dim\n",
        "    self.batch_size = batch_size\n",
        "    self.labels = labels\n",
        "    self.list_IDs = list_IDs\n",
        "    self.n_channels = n_channels\n",
        "    self.n_classes = n_classes\n",
        "    self.shuffle = shuffle\n",
        "    self.augmentation = augmentation\n",
        "    self.segmentation = segmentation\n",
        "\n",
        "    if self.augmentation:\n",
        "      self.seq = iaa.Sequential([\n",
        "                              iaa.GaussianBlur(sigma=(0.1, 3.5)),\n",
        "                              iaa.Emboss(alpha=(0.0, 1.0), strength=(0.0, 1.5)),\n",
        "                              iaa.Fliplr(0.25),\n",
        "                              iaa.Flipud(0.25),\n",
        "                              iaa.Affine(rotate=(-45, 45)),\n",
        "                              iaa.PiecewiseAffine(scale=(0.01, 0.05)),\n",
        "                              iaa.Affine(shear=(-7, 7))\n",
        "                          ])\n",
        "\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the number of steps per epoch'\n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    'Generate one batch of data'\n",
        "    # Generate indexes of the batch\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    # Find list of IDs\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "    list_labels_temp = [self.labels[k] for k in indexes]\n",
        "\n",
        "    # Generate data\n",
        "    X, y = self.__data_generation(list_IDs_temp, list_labels_temp)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    'Updates indexes after each epoch'\n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "        np.random.shuffle(self.indexes)\n",
        "\n",
        "  def hair_removal(self, src):\n",
        "    # Convert the original image to grayscale\n",
        "    #self.grayScale = cv2.cvtColor( src, cv2.COLOR_RGB2GRAY )\n",
        "    # Kernel for the morphological filtering\n",
        "    kernel = cv2.getStructuringElement(1,(17,17))\n",
        "    # Perform the blackHat filtering on the grayscale image to find the\n",
        "    # hair countours\n",
        "    blackhat = cv2.morphologyEx(self.grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
        "    # intensify the hair countours in preparation for the inpainting\n",
        "    # algorithm\n",
        "    ret,thresh2 = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n",
        "    # inpaint the original image depending on the mask\n",
        "    dst = cv2.inpaint(src,thresh2,1,cv2.INPAINT_TELEA)\n",
        "    return dst\n",
        "\n",
        "  def segment_image(self, image):\n",
        "    #self.grayScale = cv2.cvtColor( image, cv2.COLOR_RGB2GRAY )\n",
        "    th = threshold_otsu(self.grayScale)\n",
        "    mask  = self.grayScale < th\n",
        "    mask = np.stack((mask,)*3, axis=-1)\n",
        "    filtered = image * mask\n",
        "    return filtered\n",
        "\n",
        "\n",
        "  def augment_image(self, image):\n",
        "    aug_image = self.seq.augment_image(image)\n",
        "    return aug_image\n",
        "\n",
        "\n",
        "  def __data_generation(self, list_IDs_temp, list_labels_temp):\n",
        "    'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "    # Initialization\n",
        "    X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "    y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "    # Generate data\n",
        "    for i, ID in enumerate(list_IDs_temp):\n",
        "        # Store sample\n",
        "        #img = cv2.imread(ID,cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.imread(ID)\n",
        "        #print(ID)\n",
        "        img_resized = cv2.resize(img, self.dim[::-1])\n",
        "        img_resized = cv2.medianBlur(img_resized, 3)\n",
        "        self.grayScale = cv2.cvtColor( img_resized, cv2.COLOR_RGB2GRAY )\n",
        "        img_resized = self.hair_removal(img_resized)\n",
        "        # Segmentation block\n",
        "        if self.segmentation:\n",
        "          img_resized = self.segment_image(img_resized)\n",
        "        # Classical augmentation\n",
        "        if self.augmentation:\n",
        "          img_resized = self.augment_image(img_resized)\n",
        "        # GAN augmentation\n",
        "\n",
        "        #img_resized = cv2.cvtColor( img_resized, cv2.COLOR_BGR2GRAY )\n",
        "        #X[i,] =  np.expand_dims(img_resized, axis=2)\n",
        "        X[i, ] = img_resized\n",
        "        # Store class\n",
        "        y[i] = list_labels_temp[i]\n",
        "\n",
        "    return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07dThAEHTopT"
      },
      "outputs": [],
      "source": [
        "train_generator = DataGenerator(list_IDs= X_over_list, labels= y_over, n_channels=3,\n",
        "                                shuffle=True, augmentation=True, batch_size=256\n",
        "                                )\n",
        "val_generator = DataGenerator(list_IDs= X_val, labels= y_val, n_channels=3, shuffle=False, augmentation=False, batch_size=256)\n",
        "test_generator = DataGenerator(list_IDs= X_test, labels= y_test, n_channels=3, shuffle=False, augmentation=False, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'resnet'"
      ],
      "metadata": {
        "id": "wmjTHpiFQjwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EuDKrDBUj5S"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "for images, labels in train_generator:\n",
        "  print(images.shape)\n",
        "  print(labels.shape)\n",
        "  for index in range(len(labels)):\n",
        "    cv2_imshow(images[index])\n",
        "    print(labels[index])\n",
        "  break\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy folder to content**"
      ],
      "metadata": {
        "id": "8Y_BGIieAb6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/datajpg /content/drive/MyDrive/."
      ],
      "metadata": {
        "id": "-dZilL8xAaAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/datajpg.zip /content/"
      ],
      "metadata": {
        "id": "3ypQhCBdElvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDi7IzVTpIdx"
      },
      "source": [
        "# **Transfer learning**\n",
        "Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc7f808TPtFf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50 as ResNet\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Dense, Conv2D, MaxPooling2D, Flatten, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVSPP5IIpfpF"
      },
      "outputs": [],
      "source": [
        "pretrained_model = ResNet(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex9WhKmnp1y8"
      },
      "outputs": [],
      "source": [
        "pretrained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvWHaKMQp3sG"
      },
      "outputs": [],
      "source": [
        "plot_model(pretrained_model, to_file='resnet.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzHeaNXaqKVk"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(128, 128, 3))\n",
        "x = pretrained_model(input_layer)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = BatchNormalization()(x)\n",
        "output_layer = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=output_layer, name=\"transfer_learning_resnet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr0qs4TMsTnl"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSUdlMGAuvWO"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Recall(name='recall', class_id=1),\n",
        "                                                                          tf.keras.metrics.AUC(name='auc'),\n",
        "                                                                          tf.keras.metrics.Precision(name='prec', class_id=1),\n",
        "                                                                          tf.keras.metrics.Accuracy(name=\"accuracy\")\n",
        "                                                                          ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CPB8MWouvWP"
      },
      "outputs": [],
      "source": [
        "best_checkpoint = ModelCheckpoint(f'/content/drive/MyDrive/models/{MODEL_NAME}.h5',\n",
        "                                  monitor=\"val_recall\",\n",
        "                                  mode='max')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_logger = CSVLogger(f\"/content/drive/MyDrive/models/{MODEL_NAME}_logger.csv\", append=True)"
      ],
      "metadata": {
        "id": "Zp7_dkCeQfEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load model**"
      ],
      "metadata": {
        "id": "gYjCg4CokBQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications import ResNet50 as ResNet\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Dense, Conv2D, MaxPooling2D, Flatten, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import CSVLogger\n"
      ],
      "metadata": {
        "id": "osEZA348TaQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(f\"/content/drive/MyDrive/models/{MODEL_NAME}.h5\")"
      ],
      "metadata": {
        "id": "eIu97de0Tpfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_checkpoint = ModelCheckpoint(f'/content/drive/MyDrive/models/{MODEL_NAME}.h5', monitor=\"val_recall\")"
      ],
      "metadata": {
        "id": "oLJQPWkMkH6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_logger = CSVLogger(f\"/content/drive/MyDrive/models/{MODEL_NAME}_logger.csv\", append=True)"
      ],
      "metadata": {
        "id": "L0tselHsLXXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model fitting**"
      ],
      "metadata": {
        "id": "ZkvZh_b-kJgY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU0Mn0MuuvWP"
      },
      "outputs": [],
      "source": [
        "model.fit(x = train_generator,\n",
        "          validation_data = val_generator,\n",
        "          epochs=60,\n",
        "          callbacks=[best_checkpoint, csv_logger])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbwrlM8Wq8-1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating model**"
      ],
      "metadata": {
        "id": "9QFrs0G6JEu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "NCyQyLqNJIks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_classification_report(y_true, y_pred):\n",
        "  target_names = ['Normal', 'Malignant']\n",
        "  print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n"
      ],
      "metadata": {
        "id": "NjzGuesGJDFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_truth_pred(generator, model):\n",
        "  labels_all = []\n",
        "  labels_pred_all = []\n",
        "  for image, label in generator:\n",
        "        labels_pred = model.predict(image)\n",
        "        labels_pred = np.argmax(labels_pred, axis=1)\n",
        "        label = np.argmax(label, axis=1)\n",
        "        labels_pred_all.append(labels_pred)\n",
        "        labels_all.append(label)\n",
        "\n",
        "\n",
        "  return labels_all, labels_pred_all\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MOrl58dvKU3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_truth, y_val_pred = get_truth_pred(DataGenerator(list_IDs= X_val, labels= y_val, n_channels=3, shuffle=False, augmentation=False, batch_size=1),\n",
        "                                         model)"
      ],
      "metadata": {
        "id": "UehYz5T9J0ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_val)"
      ],
      "metadata": {
        "id": "Jd0jAe-3TcDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_val_pred)"
      ],
      "metadata": {
        "id": "CZCbT46zcDqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_classification_report(y_val_truth, y_val_pred)"
      ],
      "metadata": {
        "id": "ubk51qWgP8-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_truth, y_test_pred = get_truth_pred(\n",
        "    DataGenerator(list_IDs= X_test, labels= y_test, n_channels=3, shuffle=False, augmentation=False, batch_size=1)\n",
        "    , model)"
      ],
      "metadata": {
        "id": "ZhYfY16TQNkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_classification_report(y_test_truth, y_test_pred)"
      ],
      "metadata": {
        "id": "G_NQxWynQTu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BYQ0TVLDe-6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PEwWqT9Ya-S_",
        "8Y_BGIieAb6J"
      ],
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}